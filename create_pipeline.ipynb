{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient, Input, Output\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# specify the details of your subscription\n",
    "SUBSCRIPTION_ID = \"e5615bfe-b43b-41ce-bccb-b78867c2ce63\"\n",
    "RESOURCE_GROUP = \"rg-dp100-demo-001\"\n",
    "WORKSPACE_NAME = \"mlw-dp100-demo\"\n",
    "\n",
    "# get a handle to the subscription\n",
    "load_dotenv(\"python.env\")\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), \n",
    "                     subscription_id=SUBSCRIPTION_ID, \n",
    "                     resource_group_name=RESOURCE_GROUP,\n",
    "                     workspace_name=WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enable_node_public_ip: true\n",
      "id: /subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourceGroups/rg-dp100-demo-001/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-demo/computes/vmcluster-ml-dev\n",
      "idle_time_before_scale_down: 120\n",
      "location: japaneast\n",
      "max_instances: 2\n",
      "min_instances: 0\n",
      "name: vmcluster-ml-dev\n",
      "provisioning_state: Succeeded\n",
      "size: STANDARD_D2_V3\n",
      "ssh_public_access_enabled: false\n",
      "tier: dedicated\n",
      "type: amlcompute\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Retrieve an already attached Azure Machine Learning Compute.\n",
    "cluster_name = \"vmcluster-ml-dev\"\n",
    "print(ml_client.compute.get(cluster_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pathlib import Path\n",
      "from random import randint\n",
      "from uuid import uuid4\n",
      "\n",
      "# mldesigner package contains the command_component which can be used to define component from a python function\n",
      "from mldesigner import command_component, Input, Output\n",
      "\n",
      "\n",
      "@command_component()\n",
      "def train_model(\n",
      "    training_data: Input(type=\"uri_file\"),\n",
      "    max_epochs: int,\n",
      "    model_output: Output(type=\"uri_folder\"),\n",
      "    learning_rate=0.02,\n",
      ") -> str:\n",
      "    \"\"\"A dummy train component.\n",
      "\n",
      "    Args:\n",
      "        training_data: a file contains training data\n",
      "        max_epochs: max epochs\n",
      "        learning_rate: learning rate\n",
      "        model_output: target folder to save model output\n",
      "    \"\"\"\n",
      "\n",
      "    lines = [\n",
      "        f\"Training data path: {training_data}\",\n",
      "        f\"Max epochs: {max_epochs}\",\n",
      "        f\"Learning rate: {learning_rate}\",\n",
      "        f\"Model output path: {model_output}\",\n",
      "    ]\n",
      "\n",
      "    for line in lines:\n",
      "        print(line)\n",
      "\n",
      "    # Do the train and save the trained model as a file into the output folder.\n",
      "    # Here only output a dummy data for demo.\n",
      "    model = str(uuid4())\n",
      "    (Path(model_output) / \"model\").write_text(model)\n",
      "\n",
      "    return str((Path(model_output) / \"model\"))\n",
      "\n",
      "\n",
      "@command_component(\n",
      "    display_name=\"Score\",\n",
      "    # init customer environment with conda YAML\n",
      "    # the YAML file shall be put under your code folder.\n",
      "    environment=\"./env.yaml\",\n",
      "    # specify your code folder, default code folder is current file's parent\n",
      "    # code='.'\n",
      ")\n",
      "def score_data(\n",
      "    model_input: Input(type=\"uri_folder\"),\n",
      "    test_data: Input(type=\"uri_file\"),\n",
      "    score_output: Output(type=\"uri_folder\"),\n",
      "    model_file: str = None,\n",
      ") -> str:\n",
      "    \"\"\"A dummy score component.\"\"\"\n",
      "\n",
      "    lines = [\n",
      "        f\"Model path: {model_input}\",\n",
      "        f\"Model file: {model_file}\",\n",
      "        f\"Test data path: {test_data}\",\n",
      "        f\"Scoring output path: {score_output}\",\n",
      "    ]\n",
      "\n",
      "    for line in lines:\n",
      "        print(line)\n",
      "\n",
      "    # Load the model from input port\n",
      "    # Here only print the model as text since it is a dummy one\n",
      "    model = (Path(model_input) / \"model\").read_text()\n",
      "    print(\"Model:\", model)\n",
      "\n",
      "    # Do scoring with the input model\n",
      "    # Here only print text to output file as demo\n",
      "    (Path(score_output) / \"score\").write_text(\"scored with {}\".format(model))\n",
      "\n",
      "    return str(Path(score_output) / \"score\")\n",
      "\n",
      "\n",
      "@command_component(display_name=\"Evaluate\", environment=\"./env.yaml\")\n",
      "def eval_model(\n",
      "    scoring_result: Input(type=\"uri_folder\"),\n",
      "    eval_output: Output(type=\"uri_folder\"),\n",
      "    scoring_file: str = None,\n",
      "):\n",
      "    \"\"\"A dummy evaluate component.\"\"\"\n",
      "\n",
      "    lines = [\n",
      "        f\"Scoring result path: {scoring_result}\",\n",
      "        f\"Scoring file: {scoring_file}\",\n",
      "        f\"Evaluation output path: {eval_output}\",\n",
      "    ]\n",
      "\n",
      "    for line in lines:\n",
      "        print(line)\n",
      "\n",
      "    # Evaluate the incoming scoring result and output evaluation result.\n",
      "    # Here only output a dummy file for demo.\n",
      "    (Path(eval_output) / \"eval_result\").write_text(\"eval_result\")\n"
     ]
    }
   ],
   "source": [
    "with open(\"src/components.py\") as fin:\n",
    "    print(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the components as functions\n",
    "from src.components import train_model, score_data, eval_model\n",
    "\n",
    "\n",
    "custom_path = \"azureml://datastores/workspaceblobstore/paths/custom_path/${{name}}/\"\n",
    "\n",
    "# define a pipeline with component\n",
    "# the function name will be reflected on AML pipeline as the overall component\n",
    "# the variables like train_with_sample_data are component nodes in the pipeline\n",
    "@pipeline(default_compute=cluster_name)\n",
    "def pipeline_with_python_function_components(input_data, test_data, learning_rate):\n",
    "    \"\"\"E2E dummy train-score-eval pipeline with components defined via python function components\"\"\"\n",
    "\n",
    "    # Call component obj as function: apply given inputs & parameters to create a node in pipeline\n",
    "    train_with_sample_data = train_model(training_data=input_data, \n",
    "                                         max_epochs=5, \n",
    "                                         learning_rate=learning_rate\n",
    "                                         )\n",
    "    score_with_sample_data = score_data(model_input=train_with_sample_data.outputs.model_output,\n",
    "                                        test_data=test_data,\n",
    "                                        model_file=train_with_sample_data.outputs.output,\n",
    "                                        )\n",
    "    # example how to change path of output on step level,\n",
    "    # please note if the output is promoted to pipeline level you need to change path in pipeline job level\n",
    "    score_with_sample_data.outputs.score_output = Output(\n",
    "        type=\"uri_folder\", mode=\"rw_mount\", path=custom_path\n",
    "    )\n",
    "    eval_with_sample_data = eval_model(\n",
    "        scoring_result=score_with_sample_data.outputs.score_output,\n",
    "        scoring_file=score_with_sample_data.outputs.output,\n",
    "    )\n",
    "\n",
    "    # Return: pipeline outputs\n",
    "    return {\n",
    "        \"eval_output\": eval_with_sample_data.outputs.eval_output,\n",
    "        \"model_output\": train_with_sample_data.outputs.model_output,\n",
    "    }\n",
    "\n",
    "\n",
    "pipeline_job = pipeline_with_python_function_components(\n",
    "    input_data=Input(\n",
    "        path=\"wasbs://demo@dprepdata.blob.core.windows.net/Titanic.csv\", type=\"uri_file\"\n",
    "    ),\n",
    "    test_data=Input(\n",
    "        path=\"wasbs://demo@dprepdata.blob.core.windows.net/Titanic.csv\", type=\"uri_file\"\n",
    "    ),\n",
    "    learning_rate=0.1,\n",
    ")\n",
    "# example how to change path of output on pipeline level\n",
    "pipeline_job.outputs.model_output = Output(\n",
    "    type=\"uri_folder\", mode=\"rw_mount\", path=custom_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "\u001b[32mUploading src (0.01 MBs): 100%|##########| 5579/5579 [00:01<00:00, 5278.66it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>titanic_pipeline_samples</td><td>yellow_lychee_v9v60xkdjk</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/yellow_lychee_v9v60xkdjk?wsid=/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo&amp;tid=3c2288b7-c4ac-4ad8-a4f3-32a569108be3\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {'input_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000019B0B8EBD50>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000019B0BE81510>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.PipelineInput object at 0x0000019B0BE81050>}, 'outputs': {'eval_output': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x0000019B0BE82DD0>, 'model_output': <azure.ai.ml.entities._job.pipeline._io.base.PipelineOutput object at 0x0000019B0BE83FD0>}, 'jobs': {}, 'component': PipelineComponent({'intellectual_property': None, 'auto_increment_version': False, 'source': 'REMOTE.WORKSPACE.JOB', 'is_anonymous': True, 'auto_delete_setting': None, 'name': 'azureml_anonymous', 'description': 'E2E dummy train-score-eval pipeline with components defined via python function components', 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'd:\\\\Repositories\\\\GitHub\\\\dp-100', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000019B0BE81210>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline', 'display_name': 'pipeline_with_python_function_components', 'is_deterministic': None, 'inputs': {'input_data': {}, 'test_data': {}, 'learning_rate': {}}, 'outputs': {'eval_output': {}, 'model_output': {}}, 'yaml_str': None, 'other_parameter': {}, 'jobs': {'train_with_sample_data': Command({'parameters': {}, 'init': False, 'name': 'train_with_sample_data', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'd:\\\\Repositories\\\\GitHub\\\\dp-100', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000019B0B898E90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'max_epochs': '5', 'training_data': '${{parent.inputs.input_data}}', 'learning_rate': '${{parent.inputs.learning_rate}}'}, 'job_outputs': {'model_output': '${{parent.outputs.model_output}}'}, 'inputs': {'max_epochs': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0B895210>, 'training_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0B895CD0>, 'learning_rate': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0B7D7190>}, 'outputs': {'model_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000019B0B7D56D0>}, 'component': 'azureml_anonymous:339fa82d-a2e7-4b75-b1a8-c1f3be30adb8', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '2d116d5e-a263-417d-b777-c5f96a30fa2b', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'score_with_sample_data': Command({'parameters': {}, 'init': False, 'name': 'score_with_sample_data', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'd:\\\\Repositories\\\\GitHub\\\\dp-100', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000019B0BE78850>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'model_input': '${{parent.jobs.train_with_sample_data.outputs.model_output}}', 'test_data': '${{parent.inputs.test_data}}', 'model_file': '${{parent.jobs.train_with_sample_data.outputs.output}}'}, 'job_outputs': {'score_output': {'type': 'uri_folder', 'path': 'azureml://datastores/workspaceblobstore/paths/custom_path/${{name}}/', 'mode': 'rw_mount'}}, 'inputs': {'model_input': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0BB7A710>, 'test_data': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B091C44D0>, 'model_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0BE78950>}, 'outputs': {'score_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000019B0BB0A010>}, 'component': 'azureml_anonymous:cb8b689e-8ad4-47a0-bac5-0ddf3a328dbc', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': 'af094269-9ef6-4efd-9404-82de0088718b', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False}), 'eval_with_sample_data': Command({'parameters': {}, 'init': False, 'name': 'eval_with_sample_data', 'type': 'command', 'status': None, 'log_files': None, 'description': None, 'tags': {}, 'properties': {}, 'print_as_yaml': True, 'id': None, 'Resource__source_path': None, 'base_path': 'd:\\\\Repositories\\\\GitHub\\\\dp-100', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000019B0BB09C90>, 'allowed_keys': {}, 'key_restriction': False, 'logger': <Logger attr_dict (WARNING)>, 'display_name': None, 'experiment_name': None, 'compute': None, 'services': None, 'comment': None, 'job_inputs': {'scoring_result': '${{parent.jobs.score_with_sample_data.outputs.score_output}}', 'scoring_file': '${{parent.jobs.score_with_sample_data.outputs.output}}'}, 'job_outputs': {'eval_output': '${{parent.outputs.eval_output}}'}, 'inputs': {'scoring_result': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0BB08F10>, 'scoring_file': <azure.ai.ml.entities._job.pipeline._io.base.NodeInput object at 0x0000019B0BB0AB10>}, 'outputs': {'eval_output': <azure.ai.ml.entities._job.pipeline._io.base.NodeOutput object at 0x0000019B0BB0A0D0>}, 'component': 'azureml_anonymous:1193860f-b61c-4105-8167-5796e4c01228', 'referenced_control_flow_node_instance_id': None, 'kwargs': {'services': None}, 'instance_id': '216fc0a1-80f6-40f5-895a-26f54dd6bb99', 'source': 'REMOTE.WORKSPACE.COMPONENT', 'validate_required_input_not_provided': True, 'limits': None, 'identity': None, 'distribution': None, 'environment_variables': {}, 'environment': None, 'resources': None, 'queue_settings': None, 'swept': False})}, 'job_types': {'command': 3}, 'job_sources': {'REMOTE.WORKSPACE.COMPONENT': 3}, 'source_job_id': None}), 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'yellow_lychee_v9v60xkdjk', 'description': 'E2E dummy train-score-eval pipeline with components defined via python function components', 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/joshuavaple/dp-100.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': 'b269e960b0465888b3aea1fc1ee4ce2e52476af0', 'azureml.git.dirty': 'True', 'azureml.DevPlatv2': 'true', 'azureml.DatasetAccessMode': 'Asset', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'MFE', 'runType': 'HTTP', 'azureml.parameters': '{\"learning_rate\":\"0.1\"}', 'azureml.continue_on_step_failure': 'True', 'azureml.continue_on_failed_optional_input': 'True', 'azureml.enforceRerun': 'False', 'azureml.defaultComputeName': 'vmcluster-ml-dev', 'azureml.defaultDataStoreName': 'workspaceblobstore', 'azureml.pipelineComponent': 'pipelinerun'}, 'print_as_yaml': True, 'id': '/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourceGroups/rg-dp100-demo-001/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-demo/jobs/yellow_lychee_v9v60xkdjk', 'Resource__source_path': None, 'base_path': 'd:\\\\Repositories\\\\GitHub\\\\dp-100', 'creation_context': <azure.ai.ml.entities._system_data.SystemData object at 0x0000019B0BE81110>, 'serialize': <msrest.serialization.Serializer object at 0x0000019B0B893ED0>, 'display_name': 'pipeline_with_python_function_components', 'experiment_name': 'titanic_pipeline_samples', 'compute': None, 'services': {'Tracking': {'endpoint': 'azureml://japaneast.api.azureml.ms/mlflow/v1.0/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourceGroups/rg-dp100-demo-001/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-demo?', 'type': 'Tracking'}, 'Studio': {'endpoint': 'https://ml.azure.com/runs/yellow_lychee_v9v60xkdjk?wsid=/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo&tid=3c2288b7-c4ac-4ad8-a4f3-32a569108be3', 'type': 'Studio'}}, 'settings': {}, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# submit job to workspace\n",
    "pipeline_job = ml_client.jobs.create_or_update(\n",
    "    pipeline_job, experiment_name=\"titanic_pipeline_samples\"\n",
    ")\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: yellow_lychee_v9v60xkdjk\n",
      "Web View: https://ml.azure.com/runs/yellow_lychee_v9v60xkdjk?wsid=/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-01-14 15:57:29Z] Submitting 1 runs, first five are: 8786216d:d21b9ab2-601c-4b26-b1a8-650c0a967f6d\n",
      "[2024-01-14 16:04:29Z] Completing processing run id d21b9ab2-601c-4b26-b1a8-650c0a967f6d.\n",
      "[2024-01-14 16:04:31Z] Submitting 1 runs, first five are: 2d58c513:85573ac7-880a-4487-abaf-014a189ec80a\n",
      "[2024-01-14 16:06:26Z] Completing processing run id 85573ac7-880a-4487-abaf-014a189ec80a.\n",
      "[2024-01-14 16:06:27Z] Submitting 1 runs, first five are: 92c4cad2:57eb887a-a054-487b-91ce-3b44674196c6\n",
      "[2024-01-14 16:07:18Z] Completing processing run id 57eb887a-a054-487b-91ce-3b44674196c6.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: yellow_lychee_v9v60xkdjk\n",
      "Web View: https://ml.azure.com/runs/yellow_lychee_v9v60xkdjk?wsid=/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
