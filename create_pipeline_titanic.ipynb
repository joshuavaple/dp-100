{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import command, Input, MLClient, UserIdentityConfiguration, ManagedIdentityConfiguration\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes, InputOutputModes\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# specify the details of your subscription\n",
    "SUBSCRIPTION_ID = \"e5615bfe-b43b-41ce-bccb-b78867c2ce63\"\n",
    "RESOURCE_GROUP = \"rg-dp100-demo-001\"\n",
    "WORKSPACE_NAME = \"mlw-dp100-demo\"\n",
    "DATASTORE_NAME = \"blobdatastore2\"\n",
    "\n",
    "# get a handle to the subscription\n",
    "load_dotenv(\"python.env\")\n",
    "\n",
    "ml_client = MLClient(DefaultAzureCredential(), \n",
    "                     subscription_id=SUBSCRIPTION_ID, \n",
    "                     resource_group_name=RESOURCE_GROUP,\n",
    "                     workspace_name=WORKSPACE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('titanic-env', '5'), ('CliV2AnonymousEnvironment', '0'), ('pytorch-env', '1'), ('testenv-conda-002', '1'), ('testenv-conda', '1'), ('testenv', '1'), ('AzureML-AI-Studio-Development', '1'), ('AzureML-ACPT-pytorch-1.13-py38-cuda11.7-gpu', '10'), ('AzureML-ACPT-pytorch-1.12-py38-cuda11.6-gpu', '14'), ('AzureML-ACPT-pytorch-1.12-py39-cuda11.6-gpu', '14'), ('AzureML-ACPT-pytorch-1.11-py38-cuda11.5-gpu', '14'), ('AzureML-ACPT-pytorch-1.11-py38-cuda11.3-gpu', '17'), ('AzureML-responsibleai-0.21-ubuntu20.04-py38-cpu', '7'), ('AzureML-responsibleai-0.20-ubuntu20.04-py38-cpu', '9'), ('AzureML-tensorflow-2.5-ubuntu20.04-py38-cuda11-gpu', '27'), ('AzureML-tensorflow-2.6-ubuntu20.04-py38-cuda11-gpu', '26'), ('AzureML-tensorflow-2.7-ubuntu20.04-py38-cuda11-gpu', '26'), ('AzureML-sklearn-1.0-ubuntu20.04-py38-cpu', '36'), ('AzureML-pytorch-1.10-ubuntu18.04-py38-cuda11-gpu', '36'), ('AzureML-pytorch-1.9-ubuntu18.04-py37-cuda11-gpu', '44'), ('AzureML-pytorch-1.8-ubuntu18.04-py37-cuda11-gpu', '43'), ('AzureML-sklearn-0.24-ubuntu18.04-py37-cpu', '47'), ('AzureML-lightgbm-3.2-ubuntu18.04-py37-cpu', '51'), ('AzureML-pytorch-1.7-ubuntu18.04-py37-cuda11-gpu', '50'), ('AzureML-tensorflow-2.4-ubuntu18.04-py37-cuda11-gpu', '51'), ('AzureML-Triton', '23'), ('AzureML-Designer-Score', '12'), ('AzureML-VowpalWabbit-8.8.0', '40'), ('AzureML-PyTorch-1.3-CPU', '40')]\n"
     ]
    }
   ],
   "source": [
    "envs = ml_client.environments.list()\n",
    "# we can print the name and latest version of the environments\n",
    "print([(env.name, env.latest_version) for env in envs])\n",
    "env = ml_client.environments.get(name=\"titanic-env\", version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Try Reading the Data from Registered Datastore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Main Reference: \n",
    "    - Using `command()`: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-read-write-data-v2?view=azureml-api-2&tabs=python\n",
    "    - Using Pandas: https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-pipeline-python-sdk?view=azureml-api-2 \n",
    "- The path to datastore must follow this format - note the \"paths\" constant: `azureml://datastores/<data_store_name>/paths/<subfolder/file.extension>`\n",
    "- Note that the datatore was set up to connect to a specific container name, thus the container name is alrealdy treated as the root folder and not included in the path above. If the container name is specified, or any wrong path is provided, StreamNotFound error will be thrown, indicating that the data is not found with the (wrong) path.\n",
    "- The compute target must be a compute cluster, else if using compute instance, the `UserError` of not being the owner of the compute will arise (unknown reason)\n",
    "- For simplicity, if using a custom environment, use the `Environment` instance as the input to the command environment argument, instead of an address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Method 1: with command - sending the reading of the file to the compute\n",
    "# datastore_path = \"azureml://datastores/blobdatastore2/paths/titanic_train.csv\"\n",
    "# \"azureml://datastores/[a-zA-Z0-9_]+/paths/.*\"\n",
    "# data_type = AssetTypes.URI_FILE\n",
    "# mode = InputOutputModes.RO_MOUNT\n",
    "# identity = ManagedIdentityConfiguration()\n",
    "# env = ml_client.environments.get(name=\"testenv\", version=1)\n",
    "\n",
    "# inputs = {\n",
    "#     \"input_data\": Input(type=data_type, path=datastore_path, mode=mode)\n",
    "# }\n",
    "# # This command job uses the head Linux command to print the first 10 lines of the file\n",
    "# job = command(\n",
    "#     command=\"head ${{inputs.input_data}}\",\n",
    "#     inputs=inputs,\n",
    "#     environment=env,\n",
    "#     compute=\"vmcluster-ml-dev\",\n",
    "#     identity=identity,\n",
    "# )\n",
    "# # Submit the command\n",
    "# ml_client.jobs.create_or_update(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 2: we can directly read the data from the datastore using the long-form URI:\n",
    "PATH = 'titanic.csv'\n",
    "uri = f'azureml://subscriptions/{SUBSCRIPTION_ID}/resourcegroups/{RESOURCE_GROUP}/workspaces/{WORKSPACE_NAME}/datastores/{DATASTORE_NAME}/paths/{PATH}'\n",
    "df = pd.read_csv(uri)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the common env for all steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic-env:5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job_env = ml_client.environments.get(name=\"titanic-env\", version=5)\n",
    "f\"{pipeline_job_env.name}:{pipeline_job_env.version}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating the 1st Component - data_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml import command\n",
    "\n",
    "data_prep_src_dir = \"./dp100\"\n",
    "data_prep_component = command(name=\"data_prep_titanic_survival\",\n",
    "                              display_name=\"Data preparation for training\",\n",
    "                              description=\"reads input, split the input to train and test\",\n",
    "\n",
    "                              inputs={\"data\": Input(type=\"uri_folder\"),\n",
    "                                      \"test_train_ratio\": Input(type=\"number\"),\n",
    "                                     },\n",
    "\n",
    "                              outputs={\"train_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                                        \"test_data\": Output(type=\"uri_folder\", mode=\"rw_mount\"),\n",
    "                                      },\n",
    "\n",
    "                              code=data_prep_src_dir,\n",
    "                              \n",
    "                              command=\"\"\"python data_prep.py \\\n",
    "                                        --data ${{inputs.data}} --test_train_ratio ${{inputs.test_train_ratio}} \\\n",
    "                                        --train_data ${{outputs.train_data}} --test_data ${{outputs.test_data}} \\\n",
    "                                        \"\"\",\n",
    "                              environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    "                              )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mUploading dp100 (0.01 MBs): 100%|##########| 6515/6515 [00:00<00:00, 9861.54it/s] \n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component data_prep_titanic_survival with Version 2024-01-20-16-29-31-9840505 is registered\n"
     ]
    }
   ],
   "source": [
    "#  Optional:\n",
    "# Now we register the component to the workspace\n",
    "data_prep_component = ml_client.create_or_update(data_prep_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(\n",
    "    f\"Component {data_prep_component.name} with Version {data_prep_component.version} is registered\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create component 2: training (using yaml definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import Input, Output\n",
    "from azure.ai.ml import command\n",
    "\n",
    "\n",
    "train_src_dir = \"./dp100\"\n",
    "train_component = command(name = \"train_model_titanic_survival\",\n",
    "                          display_name =\"Training model\",\n",
    "                          description = \"reads input, split the input to train and test\",\n",
    "\n",
    "                          inputs = {\"train_data\": Input(type=\"uri_folder\"),\n",
    "                                  \"test_data\": Input(type=\"uri_folder\"),\n",
    "                                  \"C\": Input(type=\"number\"),\n",
    "                                  \"registered_model_name\": Input(type=\"string\")},\n",
    "\n",
    "                          outputs = {\"model\": Output(type=\"uri_folder\")},\n",
    "\n",
    "    code = train_src_dir,\n",
    "\n",
    "    command = \"\"\"\n",
    "                python train.py \\\n",
    "                --train_data ${{inputs.train_data}} \\\n",
    "                --test_data ${{inputs.test_data}} \\\n",
    "                --C ${{inputs.C}} \\\n",
    "                --registered_model_name ${{inputs.registered_model_name}} \\\n",
    "                --model ${{outputs.model}}\n",
    "             \"\"\",\n",
    "\n",
    "    environment=f\"{pipeline_job_env.name}:{pipeline_job_env.version}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component train_model_titanic_survival with Version 2024-01-20-16-29-34-1196192 is registered\n"
     ]
    }
   ],
   "source": [
    "#  Optional:\n",
    "# Now we register the component to the workspace\n",
    "train_component = ml_client.create_or_update(train_component.component)\n",
    "\n",
    "# Create (register) the component in your workspace\n",
    "print(f\"Component {train_component.name} with Version {train_component.version} is registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create pipeline from the components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `@dsl.pipeline` decorator identifies the subsequent function defines a Azure Machine Learning pipeline\n",
    "- the pipeline function can return output ports. For more info about I/O ports of the components and the pipeline, refer to: https://learn.microsoft.com/en-us/azure/machine-learning/how-to-manage-inputs-outputs-pipeline?view=azureml-api-2&tabs=cli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmlCompute({'type': 'amlcompute', 'created_on': None, 'provisioning_state': 'Succeeded', 'provisioning_errors': None, 'name': 'vmcluster-ml-dev', 'description': None, 'tags': None, 'properties': {}, 'print_as_yaml': True, 'id': '/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourceGroups/rg-dp100-demo-001/providers/Microsoft.MachineLearningServices/workspaces/mlw-dp100-demo/computes/vmcluster-ml-dev', 'Resource__source_path': None, 'base_path': 'd:\\\\Repositories\\\\GitHub\\\\dp-100', 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x000002259C67BE50>, 'resource_id': None, 'location': 'japaneast', 'size': 'STANDARD_D2_V3', 'min_instances': 0, 'max_instances': 2, 'idle_time_before_scale_down': 120.0, 'identity': None, 'ssh_public_access_enabled': False, 'ssh_settings': None, 'network_settings': None, 'tier': 'dedicated', 'enable_node_public_ip': True, 'subnet': None})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster = ml_client.compute.get(\"vmcluster-ml-dev\")\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dsl decorator tells the sdk that we are defining an Azure Machine Learning pipeline\n",
    "# the compute parameter specifies the compute target to run the pipeline on\n",
    "# \"serverless\" if running on serverless compute, this is the default if not specified\n",
    "\n",
    "from azure.ai.ml import dsl\n",
    "\n",
    "@dsl.pipeline(\n",
    "    compute=cluster,  \n",
    "    description=\"[with project package] E2E dataprep-train pipeline\",)\n",
    "\n",
    "def titanic_survival_pipeline(pipeline_job_data_input,\n",
    "                              pipeline_job_test_train_ratio,\n",
    "                              pipeline_job_C,\n",
    "                              pipeline_job_registered_model_name,):\n",
    "    \n",
    "    # calling the 2 components above in the correct order\n",
    "    # the outputs of these components can be accessed as attributes of the component\n",
    "    data_prep_job = data_prep_component(data=pipeline_job_data_input,\n",
    "                                        test_train_ratio=pipeline_job_test_train_ratio,)\n",
    "\n",
    "    train_job = train_component(train_data=data_prep_job.outputs.train_data, \n",
    "                                test_data=data_prep_job.outputs.test_data,\n",
    "                                C=pipeline_job_C,\n",
    "                                registered_model_name=pipeline_job_registered_model_name,)\n",
    "\n",
    "    return {\n",
    "        \"pipeline_job_train_data\": data_prep_job.outputs.train_data,\n",
    "        \"pipeline_job_test_data\": data_prep_job.outputs.test_data,\n",
    "        \"pipeline_job_model\": train_job.outputs.model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data asset file URI: azureml://subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo/datastores/blobdatastore2/paths/titanic.csv\n"
     ]
    }
   ],
   "source": [
    "# get a handle of the data asset and print the URI\n",
    "titanic_data = ml_client.data.get(name=\"titanic\", version=1)\n",
    "file_path = os.path.join(titanic_data.path, \"titanic.csv\")\n",
    "print(f\"Data asset file URI: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_model_name = \"titanic_survival_model_C_0.5\"\n",
    "\n",
    "# Let's instantiate the pipeline with the parameters of our choice\n",
    "pipeline = titanic_survival_pipeline(\n",
    "    pipeline_job_data_input=Input(type=\"uri_file\", path=file_path),\n",
    "    pipeline_job_test_train_ratio=0.2,\n",
    "    pipeline_job_C=0.5,\n",
    "    pipeline_job_registered_model_name=registered_model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: wheat_beach_nbfwwr7xkj\n",
      "Web View: https://ml.azure.com/runs/wheat_beach_nbfwwr7xkj?wsid=/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo\n",
      "\n",
      "Streaming logs/azureml/executionlogs.txt\n",
      "========================================\n",
      "\n",
      "[2024-01-20 16:29:42Z] Submitting 1 runs, first five are: 61dd4ce7:4e8d1743-85cb-403b-b6ac-a5c918e39461\n",
      "[2024-01-20 16:35:59Z] Completing processing run id 4e8d1743-85cb-403b-b6ac-a5c918e39461.\n",
      "[2024-01-20 16:36:00Z] Submitting 1 runs, first five are: 30e6bde9:092ecb4f-2d70-4d51-bb30-e6c94b655c42\n",
      "[2024-01-20 16:37:04Z] Completing processing run id 092ecb4f-2d70-4d51-bb30-e6c94b655c42.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: wheat_beach_nbfwwr7xkj\n",
      "Web View: https://ml.azure.com/runs/wheat_beach_nbfwwr7xkj?wsid=/subscriptions/e5615bfe-b43b-41ce-bccb-b78867c2ce63/resourcegroups/rg-dp100-demo-001/workspaces/mlw-dp100-demo\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# submit the pipeline job\n",
    "pipeline_job = ml_client.jobs.create_or_update(pipeline, experiment_name=\"titanic_survival_pipeline_on_cluster\",)\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
